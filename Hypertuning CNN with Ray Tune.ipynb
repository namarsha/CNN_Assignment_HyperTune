{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This project extends a previous project called CNN_Assignment. That project invovled building and training Convolutional Neural Networks with fully connnected layers to classify images of brains as 'Nondemented', 'Mild[ly]Demented', 'VeryMild[ly]Demented', and 'Demented.'\n",
    "\n",
    "#Much of the code is provided by the tuning with Ray Tune Tutorial here: https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html, but I have adapted it and heavily commented it to show what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, utils\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps of converting a torch training workflow into a tune workflow:\n",
    "\n",
    "* 1) wrap data loading and training in functions\n",
    "* 2) make some artificial neural network parameters configurable\n",
    "* 3) add checkpointing\n",
    "* 4) define the search space for model tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir = \"./data/Alzheimer_s Dataset\"):\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "#     with ZipFile(\"alzheimer's archive.zip\", \"r\") as zip_ref:\n",
    "#         zip_ref.extractall()\n",
    "    \n",
    "    train_data = ImageFolder(os.path.join(data_dir, '/train'),\n",
    "                            transform = transforms.Compose([\n",
    "                                transforms.Resize(140),\n",
    "                                transforms.CenterCrop(128),\n",
    "                                transforms.Grayscale(),\n",
    "                                transforms.ToTensor()\n",
    "\n",
    "                            ]))\n",
    "    \n",
    "    test_data = ImageFolder(os.path.join(data_dir, '/test'),\n",
    "                        transform = transforms.Compose([\n",
    "                            transforms.Resize(140),\n",
    "                            transforms.CenterCrop(128),\n",
    "                            transforms.Grayscale(),\n",
    "                            transforms.ToTensor()\n",
    "                            \n",
    "                        ]))\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In our definition of the model, we include two hyperparameters lin_1, corresponding to the number of nodes in the first hidden linear layer, and lin_2 corresponding t the number of nodes in the second hidden linear layer. The last layer remains 4 because that's the number of classification categories for our alzheimer's image data.\n",
    "\n",
    "#### I create a general ConvNet class and then subclass it to a ConvNetwithDropout class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, lin_1 = 100, lin_2 = 200):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #initialize the convolutional layers\n",
    "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = 8, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 8, kernel_size = 3, stride = 1, padding = 1)\n",
    "\n",
    "        \n",
    "        ##initialize the fully connected layers\n",
    "        self.fc1 = nn.Linear(in_features = 8*16*16, out_features = lin_1) #NOTE: we are using maxpool (with a kernel size of 2) thrice, so our 128 x 128 image becomes a 16x16 image.\n",
    "        self.fc2 = nn.Linear(in_features = lin_1, out_features = lin_2)\n",
    "        self.fc3 = nn.Linear(in_features = lin_2, out_features = 4)\n",
    "        \n",
    "    def forward(self, _x):\n",
    "        #Print statements below are useful for debugging shape mismatches.\n",
    "        #print(\"input shape is: {}\".format(_x.shape)) \n",
    "        _x = self.pool(F.relu(self.conv1(_x)))\n",
    "        #print(\"shape after one convolution is: {}\".format(_x.shape))\n",
    "        \n",
    "        _x = self.pool(F.relu(self.conv2(_x)))\n",
    "        #print(\"shape after two convolutions is: {}\".format(_x.shape))\n",
    "        \n",
    "        #adding more layers for assignment:\n",
    "        _x = self.pool(F.relu(self.conv2(_x)))\n",
    "        #print(\"shape after three convolutions is: {}\".format(_x.shape))\n",
    "        \n",
    "        _x = _x.view(-1, 8*16*16)\n",
    "        #print(_x.shape)\n",
    "        _x = F.relu(self.fc1(_x))\n",
    "        _x = F.relu(self.fc2(_x))\n",
    "        _x = self.fc3(_x)\n",
    "        \n",
    "        return _x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNetwithDropout(ConvNet):\n",
    "    def __init__(self, lin_1 = 100, lin_2 = 200):\n",
    "        super(ConvNetwithDropout, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, _x):\n",
    "        _x = self.pool(F.relu(self.conv1(_x)))        \n",
    "        _x = self.pool(F.relu(self.conv2(_x)))\n",
    "        _x = self.pool(F.relu(self.conv2(_x)))\n",
    "        _x = _x.view(-1, 8*16*16)\n",
    "        #print(_x.shape)\n",
    "        _x = F.relu(self.fc1(_x))\n",
    "        #DROPOUT ADDED HERE\n",
    "        _x = self.dropout(_x)\n",
    "        _x = F.relu(self.fc2(_x))\n",
    "        _x = self.fc3(_x)\n",
    "        \n",
    "        return _x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of nodes in hidden layers range between 32 and 32768. These numbers are arbitrarily chosen. Learning rate is chosen from a reciprocal continuous random variable. Batch size is chosen from batches of size  10, 20, 40 or 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"lin_1\": tune.sample_from(lambda _: 2**np.random.randint(5, 15)),\n",
    "    \"lin_2\": tune.sample_from(lambda _: 2**np.random.randint(5, 15)),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "    \"batch_size\": tune.choice([10, 20, 40, 80])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNetwithDropout(config['lin_1'], config['lin_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The train_cnn method takes as arguments a config dictionary and two directories: checkpoint, and data. These directories will store the checkpoints and data for reference in code that prints out the training data.\n",
    "\n",
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(config, checkpoint_dir=None, data_dir=None):\n",
    "\n",
    "    #Send processes to gpu if it is available. Parallelize if there are multiple gpus.\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    \n",
    "    #Define loss function/criterion and optimizer \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    \n",
    "    #If there is a checkpoint directory passed to the train_cnn function,\n",
    "    #use it to load the net and optimizer with the states preserved in the checkpoint directory.\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "        \n",
    "    #load the trainset and testset from the data_directory passed to the train_cnn function\n",
    "    trainset, testset = load_data(data_dir)\n",
    "    \n",
    "    #make train, test, and validation splits\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "    \n",
    "    \n",
    "    #make train and validation loaders\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "        \n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    \n",
    "    \n",
    "    #Begin Training loop!\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        \n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]; send both inputs and labels to device\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            ## print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "                \n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "            \n",
    "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "                torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "                \n",
    "            tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "        print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-bd77b6a8c5e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# ...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m result = tune.run(\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mresources_per_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"gpu\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dir' is not defined"
     ]
    }
   ],
   "source": [
    "gpus_per_trial = 2\n",
    "# ...\n",
    "result = tune.run(\n",
    "    partial(train_cnn, data_dir=data_dir),\n",
    "    resources_per_trial={\"cpu\": 8, \"gpu\": gpus_per_trial},\n",
    "    config=config,\n",
    "    num_samples=num_samples,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter,\n",
    "    checkpoint_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
